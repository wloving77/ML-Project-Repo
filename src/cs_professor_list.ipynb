{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5cd9f272-f256-4e3e-b9cf-130158a59a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helpers.professor_helpers' from '/home/wloving77/Githubs/school/ML-Project-Repo/src/helpers/professor_helpers.py'>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import requests\n",
    "from helpers import professor_helpers\n",
    "importlib.reload(professor_helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8595793b-292f-4a9f-aa30-c585ea35ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_helper = professor_helpers.ProfessorHelpers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "60843046-4493-4d85-9a9e-70ce168160a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://engineering.virginia.edu/department/computer-science/research/artificial-intelligence-research',\n",
       " 'https://engineering.virginia.edu/department/computer-science/research/computer-systems-research',\n",
       " 'https://engineering.virginia.edu/department/computer-science/research/cyber-physical-systems-research',\n",
       " 'https://engineering.virginia.edu/department/computer-science/research/robotics',\n",
       " 'https://engineering.virginia.edu/department/computer-science/research/security-research',\n",
       " 'https://engineering.virginia.edu/department/computer-science/research/software-engineering',\n",
       " 'https://engineering.virginia.edu/department/computer-science/research/theory']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof_helper.urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bfa48907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Madhur Behl',\n",
       " 'Rohan Chandra',\n",
       " 'Zezhou Cheng',\n",
       " 'David Evans',\n",
       " 'Farzad Farnoud',\n",
       " 'Lu Feng',\n",
       " 'Matheus Venturyne Xavier Ferreira',\n",
       " 'Ferdinando Fioretto',\n",
       " 'Tom Fletcher',\n",
       " 'Yangfeng Ji',\n",
       " 'Yen-Ling Kuo',\n",
       " 'Jundong Li',\n",
       " 'Yu Meng',\n",
       " 'Yanjun Qi',\n",
       " 'Hongning Wang',\n",
       " 'Tianhao Wang',\n",
       " 'Chen-Yu Wei',\n",
       " 'Aidong Zhang',\n",
       " 'Miaomiao Zhang',\n",
       " 'Shangtong Zhang']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof_names_AIR = prof_helper.scrape_professor_names(prof_helper.urls[0])\n",
    "prof_names_AIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "727ef869",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_names_AIR_filtered = prof_helper.filter_ids(prof_names_AIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "87def6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Lu Feng',\n",
       "  'authorId': '2117841840',\n",
       "  'paperCount': 20,\n",
       "  'citationCount': 418},\n",
       " {'name': 'Lu Feng',\n",
       "  'authorId': '47009997',\n",
       "  'paperCount': 65,\n",
       "  'citationCount': 106}]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof_names_AIR_filtered[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e3d9449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_prof_id = prof_names_AIR_filtered[17][2]['authorId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "597c708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = prof_helper.get_author_papers_with_abstracts(our_prof_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a01e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'On the Role of Server Momentum in Federated Learning',\n",
       "  'abstract': 'Federated Averaging (FedAvg) is known to experience convergence issues when encountering significant clients system heterogeneity and data heterogeneity. Server momentum has been proposed as an effective mitigation. However, existing server momentum works are restrictive in the momentum formulation, do not properly schedule hyperparameters and focus only on system homogeneous settings, which leaves the role of server momentum still an under-explored problem. In this paper, we propose a general framework for server momentum, that (a) covers a large class of momentum schemes that are unexplored in federated learning (FL), (b) enables a popular stagewise hyperparameter scheduler, (c) allows heterogeneous and asynchronous local computing. We provide rigorous convergence analysis for the proposed framework. To our best knowledge, this is the first work that thoroughly analyzes the performances of server momentum with a hyperparameter scheduler and system heterogeneity. Extensive experiments validate the effectiveness of our proposed framework. Due to page limit, we leave all proofs to the full version https://arxiv.org/abs/2312.12670.',\n",
       "  'year': 2023},\n",
       " {'title': 'Solving a Class of Non-Convex Minimax Optimization in Federated Learning',\n",
       "  'abstract': 'The minimax problems arise throughout machine learning applications, ranging from adversarial training and policy evaluation in reinforcement learning to AUROC maximization. To address the large-scale data challenges across multiple clients with communication-efficient distributed training, federated learning (FL) is gaining popularity. Many optimization algorithms for minimax problems have been developed in the centralized setting (\\\\emph{i.e.} single-machine). Nonetheless, the algorithm for minimax problems under FL is still underexplored. In this paper, we study a class of federated nonconvex minimax optimization problems. We propose FL algorithms (FedSGDA+ and FedSGDA-M) and reduce existing complexity results for the most common minimax problems. For nonconvex-concave problems, we propose FedSGDA+ and reduce the communication complexity to $O(\\\\varepsilon^{-6})$. Under nonconvex-strongly-concave and nonconvex-PL minimax settings, we prove that FedSGDA-M has the best-known sample complexity of $O(\\\\kappa^{3} N^{-1}\\\\varepsilon^{-3})$ and the best-known communication complexity of $O(\\\\kappa^{2}\\\\varepsilon^{-2})$. FedSGDA-M is the first algorithm to match the best sample complexity $O(\\\\varepsilon^{-3})$ achieved by the single-machine method under the nonconvex-strongly-concave setting. Extensive experimental results on fair classification and AUROC maximization show the efficiency of our algorithms.',\n",
       "  'year': 2023},\n",
       " {'title': 'Federated Conditional Stochastic Optimization',\n",
       "  'abstract': 'Conditional stochastic optimization has found applications in a wide range of machine learning tasks, such as invariant learning, AUPRC maximization, and meta-learning. As the demand for training models with large-scale distributed data grows in these applications, there is an increasing need for communication-efficient distributed optimization algorithms, such as federated learning algorithms. This paper considers the nonconvex conditional stochastic optimization in federated learning and proposes the first federated conditional stochastic optimization algorithm (FCSG) with a conditional stochastic gradient estimator and a momentum-based algorithm (FCSG-M). To match the lower bound complexity in the single-machine setting, we design an accelerated algorithm (Acc-FCSG-M) via the variance reduction to achieve the best sample and communication complexity. Compared with the existing optimization analysis for MAML in FL, federated conditional stochastic optimization considers the sample of tasks. Extensive experimental results on various tasks validate the efficiency of these algorithms.',\n",
       "  'year': 2023}]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THIS IS ACTUALLY Her, problem is filtering all of them to find the correct Aidong Zhang\n",
    "papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990eb49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
